# =========================
# ã®ã‚ŠfitnessAIï¼ˆRAGä¸€è²«åŒ– + ä¼šè©±ãƒ¡ãƒ¢ãƒª + å¼•ç”¨å¯è¦–åŒ– + è¨ºæ–­UI + å¹´æ˜ç¤ºï¼‰
# =========================
import os
import json
import re
import base64
import mimetypes
from pathlib import Path
from PIL import Image

# ---- Streamlit ã®ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’è»½é‡åŒ–/ç„¡åŠ¹åŒ–ï¼ˆå¿…ãš streamlit import å‰ï¼‰----
os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "poll")
# å¤§ãã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ç›£è¦–å¯¾è±¡ã‹ã‚‰å¤–ã™ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
os.environ.setdefault("STREAMLIT_SERVER_FOLDER_WATCH_BLACKLIST", "data,.git,.venv,node_modules")

import streamlit as st  # â† ã“ã“ã§åˆã‚ã¦ import

# å¿µã®ãŸã‚ã‚³ãƒ¼ãƒ‰å´ã‹ã‚‰ã‚‚é©ç”¨ï¼ˆç’°å¢ƒå¤‰æ•°ãŒåŠ¹ã‹ãªã„å ´åˆã®ä¿é™ºï¼‰
try:
    st.set_option("server.fileWatcherType", "poll")
    st.set_option("server.folderWatchBlacklist", ["data", ".git", ".venv", "node_modules"])
except Exception:
    pass

# ===== OpenAI =====
from openai import OpenAI

# st.secrets ãŒç„¡ã„ç’°å¢ƒã§ã‚‚å®‰å…¨ã«å–ã‚Šå‡ºã™ãƒ©ãƒƒãƒ‘ãƒ¼
def _safe_secret(section: str, key: str, default=None):
    try:
        sec = st.secrets  # secrets.toml ãŒç„¡ã„ã¨ã“ã“ã§ä¾‹å¤–
        return (sec.get(section, {}) or {}).get(key, default)
    except Exception:
        return default

# ã¾ãšã¯ç’°å¢ƒå¤‰æ•°ã‚’å„ªå…ˆã€‚ç„¡ã‘ã‚Œã° secrets.toml ã‹ã‚‰ï¼ˆä¸¡å¯¾å¿œï¼‰
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or _safe_secret("openai", "api_key")
if not OPENAI_API_KEY:
    st.error("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Cloud Run ã§ã¯ã€ç’°å¢ƒå¤‰æ•°ã€ã«ã€Streamlit Cloud ã§ã¯ã€Secretsã€ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
client = OpenAI(api_key=OPENAI_API_KEY)

# ===== LlamaIndex =====
from llama_index.core import StorageContext, load_index_from_storage, Settings
from llama_index.core.postprocessor import SimilarityPostprocessor
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.response_synthesizers import get_response_synthesizer

# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
def get_base64_image(image_path: str) -> str:
    if not os.path.exists(image_path): return ""
    with open(image_path, "rb") as img:
        return base64.b64encode(img.read()).decode()

def image_to_base64_str(uploaded_file) -> str:
    mime = mimetypes.guess_type(uploaded_file.name)[0] or "image/png"
    uploaded_file.seek(0)
    b64 = base64.b64encode(uploaded_file.read()).decode()
    return f"data:{mime};base64,{b64}"

def build_openai_messages(history, latest_user_content):
    msgs = []
    for m in history[-16:]:
        role, content = m["role"], m["content"]
        if isinstance(content, list):
            text_parts = [c.get("text", "") for c in content if c.get("type") == "text"]
            content = "\n".join(text_parts) if text_parts else ""
        msgs.append({"role": role, "content": content})
    msgs.append({"role": "user", "content": latest_user_content})
    return msgs

# ---- å¹´ã‚’æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ ----
YEAR_RE = re.compile(r"(20\d{2})å¹´?|(?:\()?(20\d{2})(?:\))?")

def _pick_year_from_text(text: str) -> str | None:
    if not text: return None
    m = YEAR_RE.search(text)
    if m:
        return m.group(1) or m.group(2)
    return None

def extract_year(meta: dict, preview_text: str) -> str | None:
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ¡ã‚¿æƒ…å ±ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é †ã«æ¢ç´¢
    for k in ("file_name", "document_id", "doc_id", "source", "title"):
        if k in meta and isinstance(meta[k], str):
            y = _pick_year_from_text(meta[k])
            if y: return y
    y = _pick_year_from_text(preview_text)
    return y

def fmt_sources(nodes, max_items=3, with_preview=True):
    lines = []
    for n in nodes[:max_items]:
        meta = n.node.metadata or {}
        preview = (n.node.get_content() or "").replace("\n", " ")
        year = extract_year(meta, preview) or "----"
        file_or_id = meta.get("file_name") or meta.get("document_id") or "unknown"
        page = meta.get("page_label") or meta.get("page") or ""
        score = getattr(n, "score", None)
        score_txt = f"{float(score):.3f}" if isinstance(score, (int, float)) else "n/a"
        page_txt = f" p.{page}" if page else ""
        if with_preview:
            lines.append(f"- [{year}] score={score_txt} {file_or_id}{page_txt}\n  â”” preview: {preview[:180]}â€¦")
        else:
            lines.append(f"- [{year}] score={score_txt} {file_or_id}{page_txt}")
    return "\n".join(lines)

# ---- åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’è‡ªå‹•åˆ¤å®š ----
def detect_index_dim(persist_dir: str) -> int | None:
    vf = Path(persist_dir) / "default__vector_store.json"
    if not vf.exists(): return None
    try:
        with open(vf, "r", encoding="utf-8") as f:
            data = json.load(f)
        emb_dict = data.get("embedding_dict") or data.get("embeddings") or {}
        if isinstance(emb_dict, dict) and emb_dict:
            first_vec = next(iter(emb_dict.values()))
            if isinstance(first_vec, list):
                return len(first_vec)
        dim = (data.get("metadata") or {}).get("embedding_dim")
        return int(dim) if isinstance(dim, int) else None
    except Exception:
        return None

# ========= RAG ãƒ­ãƒ¼ãƒ€ï¼ˆretrieverä¸€è²«ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ =========
INDEX_DIR = "./data"

@st.cache_resource
def load_rag(_rev: str):
    if not os.path.exists(INDEX_DIR) or not os.listdir(INDEX_DIR):
        raise FileNotFoundError(f"âŒ index ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {os.path.abspath(INDEX_DIR)}")

    detected_dim = detect_index_dim(INDEX_DIR)
    if detected_dim == 3072:
        embed_model_name = "text-embedding-3-large"      # 3072
    elif detected_dim == 1536:
        # 1536æ¬¡å…ƒã® index ã¯ text-embedding-3-small ã‹ ada-002 ã®å¯èƒ½æ€§
        # å¾Œæ–¹äº’æ›å„ªå…ˆã§ ada-002 ã‚’åˆ©ç”¨
        embed_model_name = "text-embedding-ada-002"
    else:
        embed_model_name = "text-embedding-ada-002"

    Settings.embed_model = OpenAIEmbedding(model=embed_model_name, api_key=OPENAI_API_KEY)

    # éåŒæœŸ/ç›£è¦–ã‚’ä½¿ã‚ãªã„é™çš„ãƒ­ãƒ¼ãƒ‰
    storage_context = StorageContext.from_defaults(persist_dir=INDEX_DIR)
    index = load_index_from_storage(storage_context, use_async=False)

    retriever = index.as_retriever(similarity_top_k=20)
    post = SimilarityPostprocessor(similarity_cutoff=0.45)
    synth = get_response_synthesizer(response_mode="tree_summarize")

    try:
        node_count = len(index.docstore.docs)  # type: ignore[attr-defined]
    except Exception:
        node_count = -1

    health = {
        "persist_dir": os.path.abspath(INDEX_DIR),
        "node_count": node_count,
        "detected_dim": detected_dim,
        "embed_model": embed_model_name,
    }
    return retriever, post, synth, health

# ========= UI åˆæœŸåŒ– =========
st.set_page_config(page_title="ã®ã‚ŠfitnessAI", layout="centered")
avatar_base64 = get_base64_image("ã®ã‚ŠfitnessAI (1).png")
# use_container_width ã®éæ¨å¥¨ã‚’å›é¿
st.image("ã®ã‚ŠfitnessAI.png", width="stretch")
st.title("ã®ã‚Šãƒ•ã‚£ãƒƒãƒˆãƒã‚¹AI")
st.markdown("ğŸ“¸ **é£Ÿäº‹ã‚„ç­‹ãƒˆãƒ¬ãƒ•ã‚©ãƒ¼ãƒ ã®ç”»åƒãŒã‚ã‚Œã°ã‚¢ãƒƒãƒ—ã—ã¦ã­ï¼**")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ========= RAG èª­ã¿è¾¼ã¿ =========
try:
    retriever, postproc, synthesizer, rag_health = load_rag(os.getenv("K_REVISION", "local"))
except Exception as e:
    st.error(f"âŒ RAGã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# ========= é–‹ç™ºãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¡¨ç¤ºåˆ‡æ›¿ï¼‰ =========
env_from_secrets = _safe_secret("app", "env")
debug_qp = None
try:
    debug_qp = st.query_params.get("debug")  # ?debug=1 ã§å¼·åˆ¶è¡¨ç¤º
except Exception:
    pass

DEV_MODE = (
    (os.getenv("APP_ENV") or env_from_secrets or "production") != "production"
) or (str(debug_qp).lower() in ("1", "true"))

# ã‚µã‚¤ãƒ‰ãƒãƒ¼éè¡¨ç¤ºæ™‚ã«ã‚‚å‚ç…§ã•ã‚Œã‚‹æ—¢å®šå€¤
strict = False

# ========= ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒãƒƒã‚°/è¨ºæ–­ï¼ˆé–‹ç™ºæ™‚ã®ã¿è¡¨ç¤ºï¼‰ =========
if DEV_MODE:
    with st.sidebar:
        st.header("ğŸ”§ Debug / RAG Health")
        st.write("K_REVISION:", os.getenv("K_REVISION", "local"))
        st.write("INDEX_DIR:", rag_health.get("persist_dir"))
        st.write("node_count:", rag_health.get("node_count"))
        st.write("detected_dim:", rag_health.get("detected_dim"))
        st.write("embed_model:", rag_health.get("embed_model"))
        masked = OPENAI_API_KEY[:4] + "â€¦" + OPENAI_API_KEY[-4:]
        st.write("OPENAI_API_KEY:", masked)

        strict = st.toggle("RAGå³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ ¹æ‹ ãªã—ãªã‚‰å›ç­”ã‚‚ã—ãªã„ï¼‰", value=False)

        st.subheader("ğŸ” è¨ºæ–­ã‚¯ã‚¨ãƒª")
        diag_q = st.text_input("ä¾‹: ã‚¿ãƒ³ãƒ‘ã‚¯è³ª é«˜é½¢ 1.5å€", value="äººå·¥ç”˜å‘³æ–™ ä½“é‡")
        tmp_cutoff = st.slider("similarity_cutoffï¼ˆè¨ºæ–­ç”¨ï¼‰", 0.0, 0.9, 0.45, 0.05)
        if st.button("å®Ÿè¡Œ"):
            try:
                raw_hits = retriever.retrieve(diag_q)
                st.write("raw_hits (cutoffå‰):", len(raw_hits))
                diag_post = SimilarityPostprocessor(similarity_cutoff=tmp_cutoff)
                filtered = diag_post.postprocess_nodes(raw_hits)
                st.write(f"filtered_hits (cutoffå¾Œ, {tmp_cutoff}):", len(filtered))
                st.code(fmt_sources(filtered if filtered else raw_hits, max_items=5), language="text")
            except Exception as e:
                st.write("è¨ºæ–­ã‚¨ãƒ©ãƒ¼:", e)

        if st.button("ğŸ§¹ RAGã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"):
            load_rag.clear()
            st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")

# ========= ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =========
uploaded_images = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
image_data_urls = []
if uploaded_images:
    for img in uploaded_images:
        st.image(img, width="stretch")
        image_data_urls.append(image_to_base64_str(img))

# ========= ãƒãƒ£ãƒƒãƒˆå…¥åŠ› =========
user_input = st.chat_input("è³ªå•ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã©ã†ãï¼")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("è€ƒãˆä¸­...å°‘ã€…ãŠå¾…ã¡ãã ã•ã„..."):
        try:
            raw_nodes = retriever.retrieve(user_input)
            nodes = postproc.postprocess_nodes(raw_nodes)

            # --- å¹´ãƒ’ãƒ³ãƒˆã‚’åé›† ---
            years = []
            for n in nodes[:5]:  # ä¸Šä½ã‹ã‚‰æœ€å¤§5ä»¶
                meta = n.node.metadata or {}
                preview = (n.node.get_content() or "")
                y = extract_year(meta, preview)
                if y: years.append(y)
            years_uniq = sorted(set(years), reverse=True)  # æ–°ã—ã„é †

            if nodes:
                rag_result = synthesizer.synthesize(query=user_input, nodes=nodes)
                rag_text = getattr(rag_result, "response", None) or str(rag_result) or ""
                sources_block = fmt_sources(nodes, max_items=3, with_preview=True)

                if years_uniq:
                    rag_text += "\n\n**å¹´ãƒ’ãƒ³ãƒˆï¼ˆæœ¬æ–‡ã§ä½¿ã£ã¦ï¼ï¼‰:** " + ", ".join([f"{y}å¹´" for y in years_uniq])
                rag_text += "\n\n---\n**å‚ç…§å…ƒï¼ˆä¸Šä½ï¼‰**\n" + sources_block
            else:
                rag_text = "ï¼ˆé–¢é€£ã™ã‚‹æ ¹æ‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"

        except Exception as e:
            rag_text = f"âŒ è«–æ–‡ãƒ™ãƒ¼ã‚¹ã®å›ç­”å–å¾—ã§ã‚¨ãƒ©ãƒ¼ï¼š{e}"
            nodes = []

        # --- å¹´è¡¨ç¾ã‚’å¼·åˆ¶ã™ã‚‹ system ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---
        system_prompt = (
            "ã‚ãªãŸã¯ã€ã®ã‚Šfitnessã€ã¨ã„ã†ç†è«–æ´¾ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã§ã™ã€‚"
            "ä»¥ä¸‹ã®ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ã«**å³å¯†ã«åŸºã¥ã„ã¦**å›ç­”ã—ã¦ãã ã•ã„ã€‚"
            "å°‘ãªãã¨ã‚‚ä¸€åº¦ã¯ã€YYYYå¹´ã®ç ”ç©¶ã§ã¯ã€œã€ã¨ã„ã†è¡¨ç¾ã§â€œå¹´â€ã‚’æ˜ç¤ºã—ã€"
            "å¯èƒ½ãªã‚‰è¤‡æ•°å¹´ï¼ˆä¾‹: 2025å¹´ãƒ»2023å¹´ï¼‰ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã§ç¹”ã‚Šè¾¼ã¿ã¾ã™ã€‚"
            "æ ¹æ‹ ãŒç„¡ã„å ´åˆã¯ã€æ ¹æ‹ ãªã—ã€ã¨æ˜ç¤ºã—ã€æ¨æ¸¬ã§æ–­å®šã—ãªã„ã“ã¨ã€‚"
            "å°‚é–€ç”¨èªã¯é¿ã‘ã€ä½¿ã†å ´åˆã¯çŸ­ã„èª¬æ˜ã‚’æ·»ãˆã‚‹ã“ã¨ã€‚"
            "ç”»åƒãŒã‚ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ ã‚„é£Ÿäº‹ã®å…·ä½“çš„æ”¹å–„æ¡ˆã‚‚æç¤ºã€‚"
            "ãƒˆãƒ¼ãƒ³ã¯æ˜ã‚‹ãã€é ¼ã‚Œã‚‹å…„è²´ã®ã‚ˆã†ã«ã€‚"
        )

        if strict and not nodes:
            assistant_reply = "æ ¹æ‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€ã“ã®è³ªå•ã«ã¯å›ç­”ã—ã¾ã›ã‚“ï¼ˆRAGå³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚è³ªå•ã®è¨€ã„æ›ãˆã‚„è«–æ–‡è¿½åŠ ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        else:
            latest_user_content = [
                {"type": "text",
                 "text": (
                     f"è³ªå•: {user_input}\n\n---\n"
                     f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆRAGè¦ç´„ï¼‹å‚ç…§å…ƒï¼‹å¹´ãƒ’ãƒ³ãƒˆï¼‰:\n{rag_text}\n"
                     f"---\nã“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¯„å›²ã§ã€ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"
                 )}]
            for url in image_data_urls:
                latest_user_content.append({"type": "image_url", "image_url": {"url": url}})

            try:
                messages = [{"role": "system", "content": system_prompt}]
                messages += build_openai_messages(st.session_state.messages[:-1], latest_user_content)
                resp = client.chat.completions.create(
                    model="gpt-4o",
                    temperature=0.2,
                    max_tokens=1800,
                    messages=messages,
                )
                assistant_reply = resp.choices[0].message.content
            except Exception as e:
                assistant_reply = f"âš ï¸ ChatGPTå¿œç­”ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

# ========= ãƒãƒ£ãƒƒãƒˆå±¥æ­´æç”» =========
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f"**ğŸ§â€â™‚ï¸ ã‚ãªãŸ:** {msg['content']}")
    else:
        st.markdown(
            f"""
            <div style='display: flex; align-items: flex-start; margin-top: 10px;'>
                <img src="data:image/png;base64,{avatar_base64}" width="40"
                     style="border-radius: 50%; margin-right: 10px;" />
                <div style='background-color: #f0f2f6; padding: 10px; border-radius: 10px; max-width: 85%;'>
                    {msg["content"]}
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )
