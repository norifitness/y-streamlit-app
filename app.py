import streamlit as st
import openai
import base64
import mimetypes
import os
from PIL import Image
from llama_index.core import StorageContext, load_index_from_storage

# âœ… OpenAI APIã‚­ãƒ¼
openai.api_key = st.secrets["openai"]["api_key"]

# âœ… Base64ç”»åƒå¤‰æ›ï¼ˆã‚¢ãƒã‚¿ãƒ¼ç”¨ï¼‰
def get_base64_image(image_path):
    if not os.path.exists(image_path):
        return ""
    with open(image_path, "rb") as img:
        return base64.b64encode(img.read()).decode()

avatar_base64 = get_base64_image("ã®ã‚ŠfitnessAI (1).png")

# âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ â†’ base64 URL
def image_to_base64_str(uploaded_file):
    mime = mimetypes.guess_type(uploaded_file.name)[0]
    uploaded_file.seek(0)
    base64_str = base64.b64encode(uploaded_file.read()).decode()
    return f"data:{mime};base64,{base64_str}"

# âœ… LlamaIndex èª­ã¿è¾¼ã¿
@st.cache_resource
def load_query_engine():
    index_path = "./data"
    if not os.path.exists(index_path):
        st.error("âŒ RAGç”¨ã®indexãƒ•ã‚©ãƒ«ãƒ€ï¼ˆ./dataï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Colabãªã©ã§ä½œæˆã—ã¦é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    storage_context = StorageContext.from_defaults(persist_dir=index_path)
    index = load_index_from_storage(storage_context)
    return index.as_query_engine()

query_engine = load_query_engine()

# âœ… UI è¨­å®š
st.set_page_config(page_title="ã®ã‚ŠfitnessAI", layout="centered")
st.image("ã®ã‚ŠfitnessAI.png", use_container_width=True)
st.title("ã®ã‚ŠfitnessAI")
st.markdown("ğŸ“¸ **é£Ÿäº‹ã‚„ç­‹ãƒˆãƒ¬ãƒ•ã‚©ãƒ¼ãƒ ã®ç”»åƒãŒã‚ã‚Œã°ã‚¢ãƒƒãƒ—ã—ã¦ã­ï¼**")

# âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# âœ… ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
uploaded_images = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
image_data_urls = []
if uploaded_images:
    for img in uploaded_images:
        st.image(img, use_container_width=True)
        image_data_urls.append(image_to_base64_str(img))

# âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å—ä»˜
user_input = st.chat_input("è³ªå•ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã©ã†ãï¼")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("è€ƒãˆä¸­...å°‘ã€…ãŠå¾…ã¡ãã ã•ã„..."):
        try:
            rag_result = query_engine.query(user_input)
            rag_text = rag_result.response
        except Exception as e:
            rag_text = "âŒ è«–æ–‡ãƒ™ãƒ¼ã‚¹ã®å›ç­”å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

        system_prompt = {
            "role": "system",
            "content": """
ã‚ãªãŸã¯ã€Œã®ã‚Šfitnessã€ã¨ã„ã†ç†è«–æ´¾ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã€ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ«ãƒ¼ãƒ«ã€‘

1. å°‚é–€ç”¨èªã¯æ¥µåŠ›ä½¿ã‚ãšã€åˆå¿ƒè€…ã§ã‚‚ç†è§£ã§ãã‚‹è¨€è‘‰ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
   â†’ ã‚„ã‚€ã‚’å¾—ãšä½¿ã†å ´åˆã¯ã€å¿…ãšç°¡å˜ãªèª¬æ˜ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚

2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆã¯ã€å†…å®¹ã‚’æ¨æ¸¬ã—ã¦ã€ç­‹ãƒˆãƒ¬ãƒ•ã‚©ãƒ¼ãƒ ã‚„é£Ÿäº‹å†…å®¹ã«å¯¾ã™ã‚‹å…·ä½“çš„ãªæ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚

3. ç§‘å­¦çš„æ ¹æ‹ ï¼ˆè«–æ–‡ã‚„ç ”ç©¶ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€å¯èƒ½ãªé™ã‚Š**è¤‡æ•°ã®ç ”ç©¶**ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚
   â†’ ã€Œ2023å¹´ã®ç ”ç©¶ã§ã¯ã€œã€ã€Œåˆ¥ã®ç ”ç©¶ã§ã‚‚åŒæ§˜ã®çµæœãŒå‡ºã¦ã„ã¾ã™ã€ãªã©ã€å¹´ã‚’æ˜è¨˜ã—ãªãŒã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
   â†’ æœ€æ–°ã®ç ”ç©¶ï¼ˆéå»5å¹´ä»¥å†…ï¼‰ã‚’å„ªå…ˆçš„ã«å¼•ç”¨ã—ã€ãã‚Œä»¥å‰ã®ç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

4. é›£ã—ã„è©±ã‚‚ã€ãŸã¨ãˆè©±ãƒ»æ¯”å–©ã‚’äº¤ãˆã¦åˆ†ã‹ã‚Šã‚„ã™ãï¼
   â†’ ä¾‹ï¼šã€Œç­‹è‚‰ã¯è²¯é‡‘ã¨ä¸€ç·’ã§ã™ã€‚ã‚³ãƒ„ã‚³ãƒ„è²¯ã‚ã¦ã„ãã“ã¨ã§å¢—ãˆã¦ã„ãã¾ã™ï¼ã€ã®ã‚ˆã†ã«ã€è¦ªã—ã¿ã‚„ã™ãä¼ãˆã¦ãã ã•ã„ã€‚

5. å…¨ä½“ã®ãƒˆãƒ¼ãƒ³ã¯ã€æ˜ã‚‹ãå‰å‘ãã«ï¼
   â†’ ã¾ã‚‹ã§ã‚¸ãƒ ã§éš£ã«ã„ã¦ãã‚Œã‚‹é ¼ã‚Œã‚‹å…„è²´ã®ã‚ˆã†ã«ã€å…ƒæ°—ã¥ã‘ãªãŒã‚‰ç†±ãæŒ‡å°ã—ã¦ãã ã•ã„ã€‚
"""
        }

        user_content = [{"type": "text", "text": f"{user_input}\n\nä»¥ä¸‹ã¯è«–æ–‡ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±ã§ã™ï¼š\n{rag_text}"}]
        for image_url in image_data_urls:
            user_content.append({
                "type": "image_url",
                "image_url": {"url": image_url}
            })

        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[system_prompt, {"role": "user", "content": user_content}],
                max_tokens=2000,
            )
            assistant_reply = response.choices[0].message.content
        except Exception as e:
            assistant_reply = f"âš ï¸ ChatGPTå¿œç­”ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

# âœ… ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f"**ğŸ§â€â™‚ï¸ ã‚ãªãŸ:** {msg['content']}")
    else:
        st.markdown(f"""
        <div style='display: flex; align-items: flex-start; margin-top: 10px;'>
            <img src="data:image/png;base64,{avatar_base64}" width="40" style="border-radius: 50%; margin-right: 10px;" />
            <div style='background-color: #f0f2f6; padding: 10px; border-radius: 10px; max-width: 85%;'>
                {msg["content"]}
            </div>
        </div>
        """, unsafe_allow_html=True)
